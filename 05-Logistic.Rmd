# Logistic Regression in R

*Author: Christina Knudson*

## Introduction

The previous chapter covered linear regression, which models a Gaussian response variable. In this chapter, you will learn logistic regression, which is used to model a binary response variable. Here are some examples of binary responses:

* Whether or not a person wears a helmet while biking
* Whether or not a dog is adopted
* Whether or not a beer is given an award
* Whether or not a person is charged with a crime


## Goals

In this chapter, we will cover how to...

* Fit a logistic regression model in R.
* Interpret the model.
* Calculate probabilities.
* Test the significance of regression coefficients.
* Create and interpret confidence intervals.

R's **glm** (generalized linear model) function will be the primary tool used in the chapter.


## Model Basics

Recall that  a simple linear regression model has the following form:
\[
\hat{y}_i = \beta_0 + \beta_1 x_i 
\]
where  $x_i$ is  the predictor, $\beta_0$ is the unknown regression intercept,  $\beta_1$ is the unknown regression slope, and $\hat{y}$ is the predicted response given $x_i$. 

In order to model a binary response variable, we need to introduce $p_i$, the probability of something happening. For example, this might be the probability of a person wearing a helmet, the probability of a dog being adopted, or the probability of a beer winning an award. Then our logistic regression model has the following form:
\[
\log \left( \dfrac{p_i}{1-p_i} \right) = \beta_0 + \beta_1 x_i .
\]

Recall that we estimated $\beta_0$ and $\beta_1$ to characterize the linear relationship between $x_i$ and $y_i$ in the simple linear regression setting. In the logistic regression setting, we will  estimate $\beta_0$ and $\beta_1$ in order to understand the relationship between $x_i$ and $p_i$.

As a final introductory note, we define the odds as $ \dfrac{p_i}{1-p_i} $

## Horseshoe Crab Data 

### Overview

Some females attract many males while others are unable to attract any. In this example, the females we study are horseshoe crabs. The males that cluster around a female are called "satellites." In order to understand what influences the presence of satellite crabs, researchers selected female crabs and collected data on the following characteristics:

* the color of her shell
* the condition of her spine
* the width of her carapace shell (in centimeters)
* the number of male satellites
* the weight of the female

In today's example, we will use the width of a female's shell to predict the probability of her having one or more satellites.


### Load and Look at the Data

```{r}
library(glmbb)
data(crabs)
head(crabs)
```



## Logistic Regression

### Fit the Model

To fit the model, we can use the **glm** function
```{r}
mod <- glm(y ~ width, family = binomial, data = crabs)
```
The first input is the regression formula (Response ~ Predictor),  the second input indicates that we are doing logistic regression, and the third input is the data frame. To find the regression coefficients (i.e. the estimates of $\beta_0$ and $\beta_1$), we can use the **coef** command
```{r}
coef(mod)
```

We can now enter these estimates into our logistic regression equation, just as we did in the simple linear regression setting. That is, our regression equation is 
\[
\log \left( \dfrac{p_i}{1-p_i} \right) = 12.3508 + 0.4972 \; \text{width}_i, 
\]
where $\text{width}_i$ is the width of a female crab's carapace shell and  $p_i$ is her probability of having one or more satellites.


## Interpret the Model ##

To do some basic interpretation, let's focus on the predictor's coefficient: `r round(coef(mod)[2], 4)`. First, notice this is a **positive** number. This tells us that wider crabs have **higher** chances of having one or more satellites. If the predictor's coefficient were **zero**, there would be **no** linear relationship between the width of a female's shell and her log odds of having one or more satellites. If the predictor's coefficient were **negative**, then wider crabs would have **lower** chances of having one or more satellites.

## Calculate Probabilities ##

Let's use our model for a female crab with a carapace shell that is 25 centimeters in width. (Note: this crab's shell width is within the range of our data set.) We start by simply substituting  this crab's width into our regression equation:
\begin{align*}
\log \left( \dfrac{p_i}{1-p_i} \right) &= -12.3508 + 0.4972 \; \text{width}_i \\
 &= -12.3508 + 0.4972 * 25 \\
 &= 0.0792.
\end{align*}
We could say that the log odds of a 25 cm female having satellites is about `r -12.3508 + 0.4972 * 25`, but let's make this more interpretable to everyday humans by translating this to a probability. We do this with a little algebra:

\begin{align*}
\log \left( \dfrac{p_i}{1-p_i} \right) &= 0.0792 \\
\Rightarrow \left( \dfrac{p_i}{1-p_i} \right) &= \exp(0.0792) \\
\Rightarrow p_i &= \dfrac{\exp(0.0792)}{1+\exp(0.0792)} \\
&= .5198
\end{align*}

This tells us the probability of a 25 cm wide female crab having one of more satellites is about `r round(exp(0.0792)/(1+exp(0.0792)), 4)`.


## Test the Regression Coefficient ##

In the previous chapter, you learned to use the **summary** command for a detailed summary of the model. The **summary** command works  in the logistic regression setting and produces similar output. 
```{r}
summary(mod)
```

## Create Confidence Intervals

Use the **confint** function to obtain confidence intervals for regression coefficients
```{r}
confint(mod)
```
The 95% confidence interval for $\beta_1$ reveals that ...
